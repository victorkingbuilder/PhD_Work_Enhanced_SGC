{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_loss_accuracy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We start with tudaraset\n",
    "using Flux\n",
    "using Flux: onecold, onehotbatch\n",
    "using Flux.Losses: logitbinarycrossentropy\n",
    "using Flux: DataLoader\n",
    "using GraphNeuralNetworks\n",
    "using MLDatasets: TUDataset\n",
    "using Statistics, Random\n",
    "using MLUtils\n",
    "using CUDA\n",
    "CUDA.allowscalar(false)\n",
    "\n",
    "function eval_loss_accuracy(model, data_loader, device)\n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    ntot = 0\n",
    "    for (g, y) in data_loader\n",
    "        g, y = (g, y) |> device\n",
    "        n = length(y)\n",
    "        ŷ = model(g, g.ndata.x) |> vec\n",
    "        loss += logitbinarycrossentropy(ŷ, y) * n\n",
    "        acc += mean((ŷ .> 0) .== y) * n\n",
    "        ntot += n\n",
    "    end\n",
    "    return (loss = round(loss / ntot, digits = 4),\n",
    "            acc = round(acc * 100 / ntot, digits = 2))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getdataset (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function getdataset()\n",
    "    tudata = TUDataset(\"MUTAG\")\n",
    "    display(tudata)\n",
    "    graphs = mldataset2gnngraph(tudata)\n",
    "    oh(x) = Float32.(onehotbatch(x, 0:6))\n",
    "    graphs = [GNNGraph(g, ndata = oh(g.ndata.targets)) for g in graphs]\n",
    "    y = (1 .+ Float32.(tudata.graph_data.targets)) ./ 2\n",
    "    @assert all(∈([0, 1]), y) # binary classification \n",
    "    return graphs, y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# arguments for the `train` function \n",
    "Base.@kwdef mutable struct Args\n",
    "    η = 1.0f-3             # learning rate\n",
    "    batchsize = 32      # batch size (number of graphs in each batch)\n",
    "    epochs = 200         # number of epochs\n",
    "    seed = 17             # set seed > 0 for reproducibility\n",
    "    usecuda = true      # if true use cuda (if available)\n",
    "    nhidden = 128        # dimension of hidden features\n",
    "    infotime = 10      # report every `infotime` epochs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset TUDataset:\n",
       "  name        =>    MUTAG\n",
       "  metadata    =>    Dict{String, Any} with 1 entry\n",
       "  graphs      =>    188-element Vector{MLDatasets.Graph}\n",
       "  graph_data  =>    (targets = \"188-element Vector{Int64}\",)\n",
       "  num_nodes   =>    3371\n",
       "  num_edges   =>    7442\n",
       "  num_graphs  =>    188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on CPU\n",
      "└ @ Main c:\\Users\\HP\\Desktop\\VicWorks03082024\\eSGCe_tudataset.ipynb:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   Train: (loss = 0.7044, acc = 24.0)   Test: (loss = 0.7066, acc = 31.58)\n",
      "Epoch: 10   Train: (loss = 0.4826, acc = 74.67)   Test: (loss = 0.5597, acc = 65.79)\n",
      "Epoch: 20   Train: (loss = 0.4376, acc = 77.33)   Test: (loss = 0.5244, acc = 68.42)\n",
      "Epoch: 30   Train: (loss = 0.4159, acc = 79.33)   Test: (loss = 0.4941, acc = 78.95)\n",
      "Epoch: 40   Train: (loss = 0.3899, acc = 79.33)   Test: (loss = 0.488, acc = 68.42)\n",
      "Epoch: 50   Train: (loss = 0.3673, acc = 81.33)   Test: (loss = 0.4594, acc = 78.95)\n",
      "Epoch: 60   Train: (loss = 0.377, acc = 80.0)   Test: (loss = 0.515, acc = 65.79)\n",
      "Epoch: 70   Train: (loss = 0.3234, acc = 84.0)   Test: (loss = 0.4369, acc = 78.95)\n",
      "Epoch: 80   Train: (loss = 0.3084, acc = 84.67)   Test: (loss = 0.4251, acc = 81.58)\n",
      "Epoch: 90   Train: (loss = 0.2805, acc = 87.33)   Test: (loss = 0.416, acc = 81.58)\n",
      "Epoch: 100   Train: (loss = 0.2689, acc = 86.0)   Test: (loss = 0.4196, acc = 78.95)\n",
      "Epoch: 110   Train: (loss = 0.2543, acc = 88.67)   Test: (loss = 0.4119, acc = 81.58)\n",
      "Epoch: 120   Train: (loss = 0.2573, acc = 86.0)   Test: (loss = 0.433, acc = 78.95)\n",
      "Epoch: 130   Train: (loss = 0.2515, acc = 90.67)   Test: (loss = 0.4015, acc = 84.21)\n",
      "Epoch: 140   Train: (loss = 0.2277, acc = 88.67)   Test: (loss = 0.3985, acc = 81.58)\n",
      "Epoch: 150   Train: (loss = 0.2371, acc = 90.0)   Test: (loss = 0.4278, acc = 81.58)\n",
      "Epoch: 160   Train: (loss = 0.2182, acc = 90.67)   Test: (loss = 0.4085, acc = 81.58)\n",
      "Epoch: 170   Train: (loss = 0.2109, acc = 91.33)   Test: (loss = 0.3961, acc = 81.58)\n",
      "Epoch: 180   Train: (loss = 0.21, acc = 90.67)   Test: (loss = 0.4112, acc = 84.21)\n",
      "Epoch: 190   Train: (loss = 0.2027, acc = 91.33)   Test: (loss = 0.4004, acc = 81.58)\n",
      "Epoch: 200   Train: (loss = 0.2023, acc = 91.33)   Test: (loss = 0.4107, acc = 84.21)\n"
     ]
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    args = Args(; kws...)\n",
    "    args.seed > 0 && Random.seed!(args.seed)\n",
    "\n",
    "    if args.usecuda && CUDA.functional()\n",
    "        device = gpu\n",
    "        args.seed > 0 && CUDA.seed!(args.seed)\n",
    "        @info \"Training on GPU\"\n",
    "    else\n",
    "        device = cpu\n",
    "        @info \"Training on CPU\"\n",
    "    end\n",
    "\n",
    "    # LOAD DATA\n",
    "    NUM_TRAIN = 150\n",
    "\n",
    "    dataset = getdataset()\n",
    "    train_data, test_data = splitobs(dataset, at = NUM_TRAIN, shuffle = true)\n",
    "\n",
    "    train_loader = DataLoader(train_data; args.batchsize, shuffle = true, collate = true)\n",
    "    test_loader = DataLoader(test_data; args.batchsize, shuffle = false, collate = true)\n",
    "\n",
    "    # DEFINE MODEL\n",
    "\n",
    "    nin = size(dataset[1][1].ndata.x, 1)\n",
    "    nhidden = args.nhidden\n",
    "\n",
    "    model = GNNChain(GraphConv(nin => nhidden, relu),\n",
    "                     GraphConv(nhidden => nhidden, relu),\n",
    "                     GlobalPool(mean),\n",
    "                     Dense(nhidden, 1)) |> device\n",
    "\n",
    "    opt = Flux.setup(Adam(args.η), model)\n",
    "\n",
    "    # LOGGING FUNCTION\n",
    "\n",
    "    function report(epoch)\n",
    "        train = eval_loss_accuracy(model, train_loader, device)\n",
    "        test = eval_loss_accuracy(model, test_loader, device)\n",
    "        println(\"Epoch: $epoch   Train: $(train)   Test: $(test)\")\n",
    "    end\n",
    "\n",
    "    # TRAIN\n",
    "\n",
    "    report(0)\n",
    "    for epoch in 1:(args.epochs)\n",
    "        for (g, y) in train_loader\n",
    "            g, y = (g, y) |> device\n",
    "            grads = Flux.gradient(model) do model\n",
    "                ŷ = model(g, g.ndata.x) |> vec\n",
    "                logitbinarycrossentropy(ŷ, y)\n",
    "            end\n",
    "            Flux.update!(opt, model, grads[1])\n",
    "        end\n",
    "        epoch % args.infotime == 0 && report(epoch)\n",
    "    end\n",
    "end\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_predicted_data (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function plot_predicted_data(graph,features,targets, sensor)\n",
    "    p = plot(xlabel=\"Time (h)\", ylabel=\"Normalized speed\")\n",
    "    prediction = []\n",
    "    grand_truth = []\n",
    "    for i in 1:3:length(features)\n",
    "        push!(grand_truth,targets[i][1,sensor,:])\n",
    "        push!(prediction, model(graph, features[i])[1,sensor,:]) \n",
    "    end\n",
    "    prediction = reduce(vcat,prediction)\n",
    "    grand_truth = reduce(vcat, grand_truth)\n",
    "    plot!(p, collect(1:length(features)), grand_truth, color = :blue, label = \"Grand Truth\", xticks =([i for i in 0:50:250], [\"$(i)\" for i in 0:4:24]))\n",
    "    plot!(p, collect(1:length(features)), prediction, color = :red, label= \"Prediction\")\n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `graph` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `graph` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\HP\\Desktop\\VicWorks03082024\\eSGCe_tudataset.ipynb:1"
     ]
    }
   ],
   "source": [
    "#plot_predicted_data(graph,features[301:588],targets[301:588], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
